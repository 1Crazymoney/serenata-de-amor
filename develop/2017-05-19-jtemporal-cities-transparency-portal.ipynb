{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Study on Brazilian Cities Transparency Portal\n",
    "In this dataset we have a population projection for each Brazilian city in the year of 2013.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We first collected the data with population estimatives, \n",
    "# we can use it later to do some comparisions or to use it later\n",
    "cities = pd.read_excel('../data/Cidades - estimativa 2013.xlsx',\n",
    "                       converters={'COD. UF': np.str, 'COD. MUNIC': np.str},\n",
    "                       sheetname=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5584, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for key in cities.keys():\n",
    "    data = pd.concat([data, cities[key]])\n",
    "    \n",
    "data = data.reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see 5570 rows because that's the number of cities that IBGE says that Brazil have. The different amount of rows leads me to believe there are metadata from the `.xlsx` messing with our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>population_projection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RO</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>25728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RO</td>\n",
       "      <td>11</td>\n",
       "      <td>379</td>\n",
       "      <td>Alto Alegre dos Parecis</td>\n",
       "      <td>13827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RO</td>\n",
       "      <td>11</td>\n",
       "      <td>403</td>\n",
       "      <td>Alto Paraíso</td>\n",
       "      <td>19459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RO</td>\n",
       "      <td>11</td>\n",
       "      <td>346</td>\n",
       "      <td>Alvorada D'Oeste</td>\n",
       "      <td>17399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RO</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>Ariquemes</td>\n",
       "      <td>101269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state state_id city_id                city_name population_projection\n",
       "0    RO       11      15    Alta Floresta D'Oeste                 25728\n",
       "1    RO       11     379  Alto Alegre dos Parecis                 13827\n",
       "2    RO       11     403             Alto Paraíso                 19459\n",
       "3    RO       11     346         Alvorada D'Oeste                 17399\n",
       "4    RO       11      23                Ariquemes                101269"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns={\n",
    "        'UF': 'state',\n",
    "        'COD. UF': 'state_id',\n",
    "        'COD. MUNIC': 'city_id',\n",
    "        'NOME DO MUNICÍPIO': 'city_name',\n",
    "        'POPULAÇÃO ESTIMADA': 'population_projection'\n",
    "    }, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formating `city_id`\n",
    "\n",
    "Formatting `city_id` to conform with the ids displayed on the Brazilian cesus files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['city_id'] = data['city_id'].apply(lambda x: x.zfill(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out a `unique_id` for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>population_projection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>BA</td>\n",
       "      <td>29</td>\n",
       "      <td>00108</td>\n",
       "      <td>Abaíra</td>\n",
       "      <td>9132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>DF</td>\n",
       "      <td>53</td>\n",
       "      <td>00108</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>2789761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state state_id city_id city_name population_projection\n",
       "1831    BA       29   00108    Abaíra                  9132\n",
       "5583    DF       53   00108  Brasília               2789761"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['city_id'] == '00108']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_IDS = data.loc[:,['state_id', 'city_id']]\n",
    "\n",
    "for i in range(len(UNIQUE_IDS['state_id'])):\n",
    "    UNIQUE_IDS.loc[i,'ids'] = '{}{}'.format(UNIQUE_IDS.loc[i,'state_id'],\n",
    "                                              UNIQUE_IDS.loc[i,'city_id'])\n",
    "\n",
    "UNIQUE_IDS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(UNIQUE_IDS['ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_IDS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brazilian_states = {'RO': 'rondonia',\n",
    "                    'AC': 'acre',\n",
    "                    'AM': 'amazonas',\n",
    "                    'RR': 'roraima',\n",
    "                    'PA': 'para',\n",
    "                    'AP': 'amapa',\n",
    "                    'TO': 'tocantis',\n",
    "                    'MA': 'maranhao',\n",
    "                    'PI': 'piaui',\n",
    "                    'CE': 'ceara',\n",
    "                    'RN': 'rio_grande_do_norte',\n",
    "                    'PB': 'paraiba',\n",
    "                    'PE': 'pernambuco',\n",
    "                    'AL': 'alagoas',\n",
    "                    'SE': 'sergipe',\n",
    "                    'BA': 'bahia',\n",
    "                    'MG': 'mina_gerais',\n",
    "                    'ES': 'epirito_santo',\n",
    "                    'RJ': 'rio_de_janeiro',\n",
    "                    'SP': 'sao_paulo',\n",
    "                    'PR': 'parana',\n",
    "                    'SC': 'santa_catarina', \n",
    "                    'RS': 'rio_grande_do_sul',\n",
    "                    'MS': 'mato_grosso_do_sul',\n",
    "                    'MT': 'mato_grosso',\n",
    "                    'GO': 'goias',\n",
    "                    'DF': 'distrito_federal'}\n",
    "\n",
    "census_link = \"ftp.ibge.gov.br/Censos/Censo_Demografico_2010/resultados/total_populacao_{}.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering cities with @cuducos Brazilian Cities script\n",
    "\n",
    "@cuducos had already made a script with all Brazilian Cities and its code and state associated, here in [this repository](https://github.com/cuducos/brazilian-cities).\n",
    "\n",
    "We checked and it is the best way to get the cities in the right way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serenata_toolbox.datasets import fetch\n",
    "\n",
    "fetch('2017-05-22-brazilian-cities.csv', '../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazilian_cities = pd.read_csv('../data/2017-05-22-brazilian-cities.csv')\n",
    "brazilian_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazilian_cities.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing its form\n",
    "\n",
    "It is necessary to normalize all information in order to use it to our necessities, so we managed to:\n",
    "- Lowercase all states\n",
    "- Remove all acentuation and normalize cities names\n",
    "- And for our case we remove spaces to generate the pattern we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brazilian_cities['state'] = brazilian_cities['state'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_string(string):\n",
    "    if isinstance(string, str):\n",
    "        nfkd_form = unicodedata.normalize('NFKD', string.lower())\n",
    "        return nfkd_form.encode('ASCII', 'ignore').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brazilian_cities['normalized_name'] = brazilian_cities['name'].apply(lambda x: normalize_string(x))\n",
    "brazilian_cities['normalized_name'] = brazilian_cities['normalized_name'].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazilian_cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all cities that are part of Transparency Portal\n",
    "\n",
    "There are some cities that we already know that have a page with transparency and open data. The main objective here is to find how many cities have that.\n",
    "\n",
    "Pattern: `{city}-{state}.portaltp.com.br`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portal_url = 'https://{}-{}.portaltp.com.br/'\n",
    "brazilian_cities['transparency_portal_url'] = brazilian_cities.apply(lambda row: portal_url.format(\n",
    "                                                                                        row['normalized_name'],\n",
    "                                                                                        row['state']), axis=1)\n",
    "brazilian_cities.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Getting all of the status code for each city might take a while so we added the prints only for feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "    \n",
    "def get_status(url):\n",
    "    try:\n",
    "        print(requests.head(url).status_code)\n",
    "        return requests.head(url).status_code\n",
    "    except requests.ConnectionError:\n",
    "        print(404)\n",
    "        return 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "colatina = brazilian_cities[brazilian_cities['code'] == 320150]['transparency_portal_url'].values[0]\n",
    "statusOK = get_status(colatina)\n",
    "\n",
    "abaete = brazilian_cities[brazilian_cities['code'] == 310020]['transparency_portal_url'].values[0]\n",
    "statusNOK = get_status(abaete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "br_cities = brazilian_cities.loc[:10,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "br_cities.loc[:,'status_code'] = br_cities.apply(lambda x: get_status(x['transparency_portal_url']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take too long considering we have 5570 cities to address.\n",
    "\n",
    "Let's try using [grequests](https://pypi.python.org/pypi/grequests).\n",
    "\n",
    "I know that we can find two different status code in the first 10 cities urls test. So let's use those 10 to test grequests ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import grequests\n",
    "\n",
    "rs = (grequests.get(u) for u in list(br_cities['transparency_portal_url']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exception_handler(request, exception):\n",
    "    return 404\n",
    "\n",
    "responses = grequests.map(rs, exception_handler=exception_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [int(x) for x in br_cities['status_code'].values]\n",
    "\n",
    "print(pd.unique(codes), pd.unique(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above got me wondering where were those 200 statuses code we've seen before. I tested the code on the command line and they are there. So a little reasearch and I found that apparently it is not possible to run async tasks easily on a jupyter notebook [ref](http://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Asynchronous.html).\n",
    "\n",
    "With that in mind we decided to write a script that generates the infomartion we want: Open Data url for each brazilian city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = br_cities[br_cities['status_code'] == 404].copy().reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some cities that we already know that have a page with transparency and open data but the pattern is different from the one above.\n",
    "\n",
    "Second Pattern: `cm{city}-{state}.portaltp.com.br`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portal_url = 'https://cm{}-{}.portaltp.com.br/'\n",
    "data['transparency_portal_url'] = data.apply(lambda row: portal_url.format(\n",
    "                                                                           row['normalized_name'],\n",
    "                                                                           row['state']), axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to update the status code column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data.loc[:,'status_code'] = data.apply(lambda x: get_status(x['transparency_portal_url']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study purposes\n",
    "data.loc[8, 'status_code'] = 200\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['status_code'] == 404, 'transparency_portal_url'] = None\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_cities.loc[br_cities['status_code'] == 404, 'transparency_portal_url'] = None\n",
    "br_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_columns = ['normalized_name', 'status_code']\n",
    "br_cities = pd.merge(br_cities.drop(unnecessary_columns, axis=1),\n",
    "                  data.drop(unnecessary_columns, axis=1),\n",
    "                  on=['code', 'name', 'state'], how='left')\n",
    "\n",
    "br_cities['transparency_portal_url'] = br_cities \\\n",
    "      .apply(lambda row: row['transparency_portal_url_x'] or row['transparency_portal_url_y'], axis=1)\n",
    "    \n",
    "unnecessary_columns = ['transparency_portal_url_x', 'transparency_portal_url_y']\n",
    "br_cities = br_cities.drop(unnecessary_columns, axis=1)\n",
    "br_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "After all that study, we find that in that pattern of transparency portals list there are already 270 cities.\n",
    "\n",
    "It is something like 4% of all Brazilian existing cities!\n",
    "\n",
    "Below we have a table with all those cities with portals ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_tp_portal = pd.read_csv('../data/2017-05-30-cities_with_tp_portal.csv')\n",
    "with_tp_portal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
